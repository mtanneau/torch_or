{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conjugate gradient algorithms\n",
    "\n",
    "We want to find a solution to the linear system\n",
    "$$\n",
    "Ax=b\n",
    "$$\n",
    "by solving the following quadratic program:\n",
    "$$\n",
    "\\min_{x} \\| Ax - b \\|^{2}\n",
    "$$\n",
    "\n",
    "The following functions implement a conjugate gradient, one using Numpy, the other one using Pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cg_numpy(\n",
    "    A,\n",
    "    b,\n",
    "    eps_a=10**-14,\n",
    "    eps_r=10**-14,\n",
    "    nIter_max=1000\n",
    "):\n",
    "    \"\"\"\n",
    "    Solve Ax=b with conjugate gradient on normal equations.\n",
    "    \"\"\"\n",
    "    \n",
    "    m, n = A.shape\n",
    "    \n",
    "    # initial point and residuals\n",
    "    x = np.zeros(n)\n",
    "    r = -A.T.dot(b)\n",
    "\n",
    "    p = -r\n",
    "    r_0_norm = np.linalg.norm(r)\n",
    "    beta = 0.0\n",
    "\n",
    "    keep_going = True\n",
    "    iter_count = 0\n",
    "\n",
    "    for k in range(1, nIter_max+1):\n",
    "\n",
    "        r_sqnorm = r.dot(r)\n",
    "        keep_going = (np.sqrt(r_sqnorm) > eps_a+eps_r*r_0_norm)\n",
    "\n",
    "        # keep updating while stopping criterion is not met\n",
    "        if(keep_going):\n",
    "            iter_count += 1\n",
    "            \n",
    "            # storing q speeds up computations\n",
    "            q = A.dot(p) \n",
    "\n",
    "            # compute step size\n",
    "            alpha = r_sqnorm / q.T.dot(q)\n",
    "\n",
    "            # perform update on x\n",
    "            x += alpha*p\n",
    "\n",
    "            # compute new conjugate gradient\n",
    "            r +=  alpha*A.T.dot(q)\n",
    "\n",
    "            beta =  r.dot(r)/ r_sqnorm\n",
    "            p =  - r+beta*p\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    print('{} iterations'.format(iter_count))\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cg_torch(\n",
    "    A,\n",
    "    b,\n",
    "    eps_a=10**-14,\n",
    "    eps_r=10**-14,\n",
    "    nIter_max=1000\n",
    "):\n",
    "    \"\"\"\n",
    "    Solve Ax=b with conjugate gradient on normal equations.\n",
    "    \"\"\"\n",
    "    \n",
    "    m, n = A.size()\n",
    "    \n",
    "    # initial point and residuals\n",
    "    x = torch.DoubleTensor(n).zero_().cuda()\n",
    "    r = -torch.matmul(torch.t(A), b)\n",
    "\n",
    "    p = -r\n",
    "    r_0_norm = torch.norm(r)\n",
    "    beta = 0.0\n",
    "\n",
    "    keep_going = True\n",
    "    iter_count = 0\n",
    "\n",
    "    for k in range(1, nIter_max+1):\n",
    "\n",
    "        r_sqnorm = torch.matmul(r, r)\n",
    "        keep_going = (np.sqrt(r_sqnorm) > eps_a+eps_r*r_0_norm)\n",
    "\n",
    "        # keep updating while stopping criterion is not met\n",
    "        if(keep_going):\n",
    "            iter_count += 1\n",
    "            \n",
    "            # storing q speeds up computations\n",
    "            q = torch.matmul(A, p)\n",
    "\n",
    "            # compute step size\n",
    "            alpha = r_sqnorm / (torch.matmul(q, q))\n",
    "\n",
    "            # perform update on x\n",
    "            x += alpha * p\n",
    "\n",
    "            # compute new conjugate gradient\n",
    "            r +=  alpha * torch.matmul(torch.t(A), q)\n",
    "\n",
    "            beta =  torch.matmul(r, r) / r_sqnorm\n",
    "            p =  -r + beta * p\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    print('{} iterations'.format(iter_count))\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical tests\n",
    "\n",
    "Compare the performance of both methods on numerical examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dimensions\n",
    "m, n = 1000, 1000\n",
    "\n",
    "# create matrix and right hand side\n",
    "A = np.random.rand(m, n)\n",
    "b = np.ones(m)\n",
    "\n",
    "A_ = torch.DoubleTensor(A).cuda()\n",
    "b_ = torch.DoubleTensor(b).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 iterations\n",
      "0.2825129999999998\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "x_ = cg_torch(A_, b_)\n",
    "end = time.clock()\n",
    "\n",
    "print((end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 iterations\n",
      "1.8259469999999998\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "x = cg_numpy(A, b)\n",
    "end = time.clock()\n",
    "\n",
    "print((end-start))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
